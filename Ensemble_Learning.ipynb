{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment :- Ensemble Learning"
      ],
      "metadata": {
        "id": "R5gX2obWxjVw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 What is Ensemble Learning in machine learning? Explain the key idea behind it.\n",
        "Answer:\n",
        "\n",
        "Ensemble Learning is a machine learning technique where multiple models (often called “weak learners” or “base learners”) are trained and then combined to make predictions.\n",
        "The idea is that while individual models may make errors, combining their predictions can reduce overall error and improve accuracy.\n",
        "Key idea:\n",
        "“A group of weak models, when combined properly, can perform better than any single strong model.”\n",
        "Why it works:\n",
        "Different models may capture different patterns in the data.\n",
        "Errors made by one model can be corrected by others.\n",
        "Combining predictions reduces the impact of noise and overfitting.\n",
        "Types of Ensemble methods:\n",
        "Bagging (Bootstrap Aggregating) - reduces variance.\n",
        "Boosting - reduces bias and variance.\n",
        "Stacking - combines multiple model types using a meta-model.\n",
        "\n",
        "\n",
        "## 2 What is the difference between Bagging and Boosting?\n",
        "Answer:\n",
        "\n",
        "1)\n",
        "Feature:- Goal\n",
        "Bagging:- Reduce variance\n",
        "Boosting:- Reduce bias (and variance)                                                                                             \n",
        "2)\n",
        "Feature:- Training data\n",
        "Bagging:- Each model gets a random bootstrap sample (sampling with replacement)\n",
        "Boosting:- Models are trained sequentially, each focusing on the errors of the previous model\n",
        "\n",
        "3)\n",
        "Feature:- Model training\n",
        "Bagging:- Models are trained independently\n",
        "Boosting:- Each new model depends on the previous one\n",
        "\n",
        "4)\n",
        "Feature:- Weighting of samples\n",
        "Bagging:- All samples have equal weight\n",
        "Boosting:- Misclassified samples get higher weight in the next round\n",
        "\n",
        "5)\n",
        "Feature:- Combination of predictions\n",
        "Bagging:- Simple majority vote (classification) or average (regression)\n",
        "Boosting:- Weighted vote (classification) or weighted sum (regression)\n",
        "\n",
        "6)\n",
        "Feature:- Example algorithms\n",
        "Bagging:- Random Forest, Bagged Decision Trees\n",
        "Boosting:- AdaBoost, Gradient Boosting, XGBoost\n",
        "\n",
        "Simple analogy:\n",
        "Bagging = “Many people vote independently — the majority wins.”\n",
        "Boosting = “One person speaks, makes mistakes, the next person learns from those mistakes and improves the answer.”\n",
        "\n",
        "\n",
        "## 3 What is bootstrap sampling and what role does it play in Bagging methods like Random Forest?\n",
        "Answer:\n",
        "\n",
        "Bootstrap sampling is a resampling technique where we create new training datasets by randomly selecting samples from the original dataset with replacement.\n",
        "“With replacement” means that after picking a sample, we put it back into the dataset before picking the next one — so the same sample can appear multiple times in one bootstrap dataset.\n",
        "Role in Bagging (e.g., Random Forest):\n",
        "Each base learner (like a decision tree) is trained on a different bootstrap sample.\n",
        "This introduces diversity among models, because each model sees a slightly different subset of the data.\n",
        "When predictions from these diverse models are averaged (or voted), variance is reduced and the overall model becomes more stable and accurate.\n",
        "Example:\n",
        "If you have 1,000 samples, a bootstrap sample also contains 1,000 points — but some points are repeated and some are missing. On average, about 63.2% of the original points are included in each bootstrap sample, and the rest are excluded (these excluded ones are the Out-of-Bag samples, explained next).\n",
        "\n",
        "\n",
        "## 4 What are Out-of-Bag (OOB) samples and how is OOB score used to evaluate ensemble models?\n",
        "Answer:\n",
        "\n",
        "Out-of-Bag (OOB) samples are the data points not included in a particular bootstrap sample.\n",
        "Since bootstrap sampling is done with replacement, about 36.8% of the original data is not selected in each sample — these are the OOB samples for that model.\n",
        "OOB Score in evaluation:\n",
        "In Bagging methods like Random Forest, we can use OOB samples as a free validation set.\n",
        "For each data point:\n",
        "Look at predictions from only the models where this point was OOB.\n",
        "Compare the aggregated prediction to the true label.\n",
        "The OOB score is simply the accuracy (or R² in regression) computed from these OOB predictions.\n",
        "Benefits of OOB evaluation:\n",
        "No need to create a separate validation set — the OOB method internally estimates the generalization performance.\n",
        "It's efficient because it uses data already generated during training.\n",
        "\n",
        "\n",
        "## 5 Compare feature importance analysis in a single Decision Tree vs.\n",
        "Answer:\n",
        "\n",
        "Feature importance in a single Decision Tree\n",
        "In a decision tree, feature importance is calculated based on how much each feature reduces impurity (such as Gini impurity or entropy) when it is used to split the data. Every time the tree splits on a feature, the reduction in impurity from that split is added to that feature's importance score. After the tree is built, the scores are normalized so they sum to 1.\n",
        "However, this approach can be unstable — small changes in the training data can lead to a different tree structure, and therefore very different importance scores. It can also be biased toward features with many unique values (for example, continuous numerical variables), which tend to produce bigger impurity reductions.\n",
        "Feature importance in a Random Forest\n",
        "A random forest is an ensemble of many decision trees, each trained on a different bootstrap sample of the data and often with a random subset of features considered at each split. For feature importance, the forest computes the same impurity reduction score for each tree individually, then averages these scores across all trees.\n",
        "This averaging process makes the importance values much more stable and less sensitive to noise or small changes in the dataset. Since each tree sees different subsets of data and features, the bias toward high-cardinality features is also reduced. While the importance scores in a random forest are more reliable, they are less directly interpretable than a single tree's top splits, because the scores come from an aggregate of many models rather than one clear structure."
      ],
      "metadata": {
        "id": "sS2_5yNEySC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# 1. Load the Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "feature_names = data.feature_names\n",
        "\n",
        "# 2. Train a Random Forest Classifier\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X, y)\n",
        "\n",
        "# 3. Get feature importance scores\n",
        "importances = model.feature_importances_\n",
        "\n",
        "# 4. Create a DataFrame for better readability\n",
        "feature_importance_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': importances\n",
        "})\n",
        "\n",
        "# 5. Sort features by importance in descending order\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# 6. Print top 5 features\n",
        "print(\"Top 5 Most Important Features:\")\n",
        "print(feature_importance_df.head(5).to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUk5pIgE4K0d",
        "outputId": "b1278410-fb5a-4fee-aacd-436329d780ec"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Most Important Features:\n",
            "             Feature  Importance\n",
            "          worst area    0.139357\n",
            "worst concave points    0.132225\n",
            " mean concave points    0.107046\n",
            "        worst radius    0.082848\n",
            "     worst perimeter    0.080850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Load the Iris dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# 2. Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Train a single Decision Tree Classifier\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "dt_pred = dt_model.predict(X_test)\n",
        "dt_accuracy = accuracy_score(y_test, dt_pred)\n",
        "\n",
        "# 4. Train a Bagging Classifier using Decision Trees (new parameter name: estimator)\n",
        "bagging_model = BaggingClassifier(\n",
        "    estimator=DecisionTreeClassifier(),\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "bagging_model.fit(X_train, y_train)\n",
        "bagging_pred = bagging_model.predict(X_test)\n",
        "bagging_accuracy = accuracy_score(y_test, bagging_pred)\n",
        "\n",
        "# 5. Print results\n",
        "print(\"Single Decision Tree Accuracy: {:.2f}%\".format(dt_accuracy * 100))\n",
        "print(\"Bagging Classifier Accuracy: {:.2f}%\".format(bagging_accuracy * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYxRCFFt5JyK",
        "outputId": "a7bf50d4-e36f-4dbe-a256-c2d4603b10a6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Single Decision Tree Accuracy: 100.00%\n",
            "Bagging Classifier Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# 1. Load the Iris dataset\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# 2. Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Define the model\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# 4. Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],   # Number of trees\n",
        "    'max_depth': [None, 5, 10]        # Maximum depth of trees\n",
        "}\n",
        "\n",
        "# 5. Use GridSearchCV for tuning\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=rf,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,               # 5-fold cross-validation\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1           # Use all CPU cores\n",
        ")\n",
        "\n",
        "# 6. Fit the grid search to the training data\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 7. Best parameters\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# 8. Evaluate the best model on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Final Accuracy on Test Set: {:.2f}%\".format(accuracy * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykrNBtmU5N8b",
        "outputId": "9a9ffb12-b653-420d-e804-0d81113479e8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': None, 'n_estimators': 100}\n",
            "Final Accuracy on Test Set: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# 1. Load the California Housing dataset\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# 2. Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# 3. Train Bagging Regressor with Decision Tree as base estimator\n",
        "bagging_regressor = BaggingRegressor(\n",
        "    estimator=DecisionTreeRegressor(),\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "bagging_regressor.fit(X_train, y_train)\n",
        "bagging_preds = bagging_regressor.predict(X_test)\n",
        "bagging_mse = mean_squared_error(y_test, bagging_preds)\n",
        "\n",
        "# 4. Train Random Forest Regressor\n",
        "rf_regressor = RandomForestRegressor(\n",
        "    n_estimators=50,\n",
        "    random_state=42\n",
        ")\n",
        "rf_regressor.fit(X_train, y_train)\n",
        "rf_preds = rf_regressor.predict(X_test)\n",
        "rf_mse = mean_squared_error(y_test, rf_preds)\n",
        "\n",
        "# 5. Print comparison\n",
        "print(f\"Bagging Regressor MSE: {bagging_mse:.4f}\")\n",
        "print(f\"Random Forest Regressor MSE: {rf_mse:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6gG1liN5u5v",
        "outputId": "fb7e0b17-98c0-43cb-cfe0-23a877e2a34b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Regressor MSE: 0.2579\n",
            "Random Forest Regressor MSE: 0.2577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10\n",
        "\n",
        "1. Choosing between Bagging and Boosting\n",
        "I would start by analyzing the problem type. Loan default prediction is a binary classification task that usually suffers from class imbalance (more “non-default” than “default” cases).\n",
        "If my base models are high variance (e.g., decision trees) and I want to reduce overfitting, I would lean toward Bagging methods like Random Forest.\n",
        "If my base models are underfitting (low bias but high error on both training and test sets), I would choose Boosting methods like XGBoost, LightGBM, or AdaBoost, since they sequentially focus on hard-to-classify customers and reduce bias.\n",
        "In practice, I would experiment with both, but boosting often performs better in structured/tabular financial data.\n",
        "\n",
        "2. Handling Overfittin\n",
        "For Bagging:\n",
        "Limit tree depth (max_depth) to prevent overly complex trees.\n",
        "Increase n_estimators until performance stabilizes.\n",
        "For Boosting:\n",
        "Use a lower learning rate (learning_rate) with more estimators.\n",
        "Apply regularization (max_depth, min_child_weight, subsample, colsample_bytree).\n",
        "Early stopping based on validation performance.\n",
        "Apply cross-validation to detect overfitting before deployment.\n",
        "\n",
        "3. Selecting Base Models\n",
        "For bagging: Decision trees are a good choice because they have high variance and benefit from averaging.\n",
        "For boosting: Decision trees (usually shallow, max_depth=3-6) are also common because they are weak learners that boosting can improve.\n",
        "Could also test logistic regression, SVM, or neural networks depending on computational budget, but decision trees are most interpretable in finance.\n",
        "\n",
        "4. Evaluating Performance using Cross-Validation\n",
        "Use Stratified K-Fold Cross-Validation to preserve the class distribution in each fold.\n",
        "Metrics to evaluate:\n",
        "AUC-ROC → Measures ability to separate default vs non-default cases.\n",
        "Precision-Recall AUC → More informative for imbalanced datasets.\n",
        "F1-score → Balances precision and recall for the “default” class.\n",
        "Ensure results are averaged across folds to avoid bias from one split.\n",
        "\n",
        "5. Justifying Ensemble Learning in this Real-World Context\n",
        "\n",
        "Loan default prediction requires high accuracy because false negatives (predicting “no default” but actually defaulting) can cause large financial losses.\n",
        "Ensemble learning improves decision-making by:\n",
        "Combining multiple weak learners to reduce variance (bagging) or bias (boosting).\n",
        "Handling noisy features and correlated variables better than a single model.\n",
        "Providing more stable predictions, which increases trust from stakeholders.\n",
        "Allowing feature importance analysis to help risk managers understand key drivers of default.\n",
        "\n",
        "✅ Final takeaway:\n",
        "In loan default prediction, I would begin with Boosting (e.g., XGBoost) for its ability to capture complex relationships and handle imbalanced data effectively, validate performance with Stratified K-Fold CV, apply regularization to prevent overfitting, and justify the approach to management based on improved stability, accuracy, and interpretability compared to single models."
      ],
      "metadata": {
        "id": "y0i4gswy6nQI"
      }
    }
  ]
}